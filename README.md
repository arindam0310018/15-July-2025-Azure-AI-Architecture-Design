# AZURE AI ARCHITECTURE & DESIGN:-

In order to adopt AI based workloads in a consistent and production ready way, __An Azure AI Landing Zone is a MUST.__

| <img src="/Images/1-Banner.jpg"> |
| --------- |

| ðŸ“Œ WHY AZURE AI LANDING ZONE IS REQUIRED:- |
| --------- |
| ðŸŽ¯ __Standardization__ - Develop and Promote the use of Blueprint(Predefined Templates) to deploy AI Services. |
| ðŸŽ¯ __Faster Time to Market__ - Less time on Infrastructure, more focus on building AI solutions. |
| ðŸŽ¯ __Security__ - Azure Policies, Network Isolation, Use of Managed Identities, RBAC, Encryption at rest/transit, Certificates. |
| ðŸŽ¯ __Scalability__ - Support onboarding of New AI Uses cases without Re-Architecture. |
| ðŸŽ¯ __Operational Excellence__ - Implementation of Observability and FinOps. Addtionally for AI Lifecycle Management, DevOps/MLOps working Hand to Hand. |

| ðŸš€ AGENDA:- |
| --------- |
| __ðŸ’¡Myths of AI Engineering.__ |
| __ðŸ’¡Myths of Data Science.__ |
| __ðŸ’¡Breakdown of AI based on Technology and Implementation.__ |
| __ðŸ’¡Breakdown of AI based on User interactions and Development.__ |
| __ðŸ’¡How All Fits Together.__ |
| __ðŸ’¡Decision Tree.__ |
| __ðŸ’¡Hub and Spoke Model for AI.__ |
| __ðŸ’¡Classical ML Architecture.__ |
| __ðŸ’¡Analytics Platform Architecture.__ |
| __ðŸ’¡Low Code No Code Architecture.__ |
| __ðŸ’¡Importance of MLOps.__ |
| __ðŸ’¡Consumption Model - APIM and MCP.__ |
| __ðŸ’¡How AI Team Structure Looks Like.__ |

| ðŸ“Œ MYTHS OF AI ENGINEERING:- |
| --------- |
| <img src="/Images/2-Myth-AI-Engineering-1.jpg"> |
| <img src="/Images/3-Myth-AI-Engineering-2.jpg"> |

| ðŸ“Œ MYTHS OF DATA SCIENCE:- |
| --------- |
| <img src="/Images/4-Myth-Data-Science.jpg"> |

| ðŸ“Œ BREAKDOWN OF AI BASED ON TECHNOLOGY & IMPLEMENTATION:- |
| --------- |
| __âœ… Machine Learning.__|
| __âœ… Deep Learning.__|
| __âœ… Natural Language Processing.__|

| ðŸ“Œ BREAKDOWN OF AI BASED ON USER INTERACTIONS & DEVELOPMENT:- |
| --------- |
| __âœ… Low Code No Code AI.__|
| __âœ… Generative AI.__|
| __âœ… Conversational AI.__|

| ðŸ“Œ HOW ALL FITS TOGETHER:- |
| --------- |
| __ðŸ“¦ Machine Learning in LOW CODE NOT CODE; GEN AI; CONVERSATIONAL AI__ |
| <img src="/Images/5-Classical-Machine-Learning.jpg"> |
| __ðŸ“¦ Deep Learning in LOW CODE NOT CODE; GEN AI; CONVERSATIONAL AI__ |
| <img src="/Images/6-Deep-Learning.jpg"> |
| __ðŸ“¦ Natural Language Processing in LOW CODE NOT CODE; GEN AI; CONVERSATIONAL AI__ |
| <img src="/Images/7-NLP.jpg"> |

| ðŸ“Œ DECISION TREE:- |
| --------- |
| <img src="/Images/8-AI-Decision-Tree.jpg"> |

| ðŸ“Œ HUB & SPOKE MODEL FOR AI:- |
| --------- |
| <img src="/Images/10-AI-Architecture -Hub-Spoke.jpg"> |

| ðŸ“Œ CLASSICAL ML ARCHITECTURE:- |
| --------- |
| <img src="/Images/11-Classical-ML-Architecture.jpg"> |

| ðŸ“Œ ANALYTICS PLATFORM ARCHITECTURE:- |
| --------- |
| __REALTIME USE CASE__ |
| <img src="/Images/12-Analytics-Platform-Architecture.jpg"> |

| ðŸ“Œ NATIVE FEATURES OF APIM:- |
| --------- |
| __ðŸš€ "Load Balance" Multiple Backend APIs.__ |
| __ðŸš€ Authentication__ |
| __âœ… APIM Service will call the Backend APIs on behalf of Application using Managed Identity.__ |
| __âœ… Managed Identity should have the right RBAC to access the Backend APIs.__ |
| __âœ… In order to secure how application access APIM, we can apply authentication on the application level. App will be authenticated with APIM Subscription Key to access the correct Backend API configured in APIM using Managed Identity.__ |
| __âœ… There can be repeated requests to backend APIs. For such use case, we use "APIM Caching"__ |
| __âœ… Tracing - logs and metrics for troubleshooting.__ |
| __âœ… Define a Mock API.__ |
| __âœ… Fetch Logs and Metrics from Azure Monitor.__
| __ðŸš€ Define Policy and apply for each API. Policies in APIM are XML Definition.__ |
| __ðŸš€ APIM Authentication Features defined in Pt 2, works well with Backend APIs and LLM Models - OpenAI, Mistral.... Multiple requests can be load balanced & send to Multiple instances of LLMS. In such Scenarios, using below features of LBs can be very useful - Priority, Weight, Retry, Circuit Breaker.__ |

| ðŸ“Œ GEN AI CAPABILITY IN APIM:- |
| --------- |
| __ðŸš€ LLM Token Limit__ |
| __Limitations/Constraints of LLM:__ âœ… No. of Tokens available per model; âœ… No. of Tokens per region |
| __Mitigation:__ âœ… Create LLM instance in different regions and use Priority and Weight to prioritize the LLM instance; âœ… With retry, we detect, if we have hit the limitation of any LLM Instances. if yes, then retry on the next available LLM instances in other region. |
| Now in order to avoid hitting limitation in each LLM instance (Per model and/or Per region), there is "a new GENAI capability available in APIM" - __"LLM Token Limit"__. This is available using APIM Policy. This will allow APIM to limit, No of tokens issued by Application or by user to specific LLM Models. |
| __ðŸš€ LLM Token Limit__ |
| Applying Policy using this feature, we can get specific metrics related to LLMs: |
| __âœ… No of Tokens consumed.__ |
| __âœ… No of remaining tokens.__ |
| __âœ… Tokens available per applications.__ |


